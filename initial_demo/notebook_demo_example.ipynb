{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663861f2-222a-4f5c-add9-27f8d0e4e838",
   "metadata": {},
   "source": [
    "## Get Data and load to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5a8691-932f-4832-83c0-3cc92a8117c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import re\n",
    "import tarfile\n",
    "from io import StringIO\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac97e91-9305-4cc8-9750-d4dc00b8836a",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "- Identify location on S3 with the train & test data\n",
    "- Define the git repo that houses the code that will be executed (train.py)\n",
    "- Define the output location and infrastructure requirements\n",
    "- Launch the training job\n",
    "\n",
    "We're using the AWS maintained Scikit image for this training job, leveraged through the sagemaker SDK. You can also leverage other similar images (PyTorch, Tensorflow etc...), or just roll your own container image completely (registered through ECS). This is simpler as no customization is required, but if customization is necessary, defining your own container is a great solution.\n",
    "\n",
    "When the training job is launched, it launches a different dedicated compute instance(s) where the model runs. The instance is only up and running for as long as the model is running (and only charged for that amount of time as well). At the conclusion of the job, the model is saved to an S3 location, as well as any data if desired. This is just a single job with fixed hyperparameters, but the job can be adjusted for hyperparameter optimization as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2342269f-b663-489d-8aa9-323188019b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/base_serializers.py:28: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.22.4)\n",
      "  import scipy.sparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define git config\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "git_config = {'repo': 'https://github.com/WesleyPasfield/sagemaker_demo.git'}\n",
    "framework_version = '1.2-1' # Scikit version - needed using Scikit SDK\n",
    "output_root = 'housingdemo/output'\n",
    "s3_bucket = 'censussmdemo'\n",
    "s3_location_train = 'housingdemo/train/train.csv'\n",
    "s3_location_test = 'housingdemo/test/test.csv'\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir='initial_demo',\n",
    "    role=get_execution_role(),\n",
    "    framework_version=framework_version,\n",
    "    output_path= f's3://{s3_bucket}/{output_root}/model_output/',\n",
    "    instance_count=1, # Flexibility if parallizable\n",
    "    instance_type=\"ml.m5.large\",  # Flexibility to scale up if needed\n",
    "    base_job_name=\"rf-scikit\",\n",
    "    use_spot_instances=True, # Keep it cheap\n",
    "    max_wait=1000, # Needed when using spot\n",
    "    max_run = 800, # Needed when using spot\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"max_depth\": 4,\n",
    "        \"target\": \"target\"\n",
    "    },\n",
    "    git_config=git_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c5c35a-82fb-42ec-b8e9-d97eb32f5774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/tmp/tmpl8mnmplz'...\n",
      "INFO:sagemaker:Creating training-job with name: rf-scikit-2024-09-16-17-54-45-674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-16 17:54:47 Starting - Starting the training job...\n",
      "2024-09-16 17:55:00 Starting - Preparing the instances for training...\n",
      "2024-09-16 17:55:50 Downloading - Downloading the training image........\u001b[34m2024-09-16 17:57:01,276 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,280 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,283 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,304 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,552 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,556 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,578 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,581 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,601 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,604 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,621 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_depth\": 4,\n",
      "        \"min-samples-leaf\": 3,\n",
      "        \"n-estimators\": 100,\n",
      "        \"target\": \"target\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"rf-scikit-2024-09-16-17-54-45-674\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://censussmdemo/rf-scikit-2024-09-16-17-54-45-674/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"max_depth\":4,\"min-samples-leaf\":3,\"n-estimators\":100,\"target\":\"target\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://censussmdemo/rf-scikit-2024-09-16-17-54-45-674/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max_depth\":4,\"min-samples-leaf\":3,\"n-estimators\":100,\"target\":\"target\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"rf-scikit-2024-09-16-17-54-45-674\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://censussmdemo/rf-scikit-2024-09-16-17-54-45-674/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--max_depth\",\"4\",\"--min-samples-leaf\",\"3\",\"--n-estimators\",\"100\",\"--target\",\"target\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=4\u001b[0m\n",
      "\u001b[34mSM_HP_MIN-SAMPLES-LEAF=3\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=target\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py --max_depth 4 --min-samples-leaf 3 --n-estimators 100 --target target\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,622 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:01,622 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34mreading data\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    1.6s\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\u001b[0m\n",
      "\u001b[34mComputing model metrics on test set\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\u001b[0m\n",
      "\u001b[34mMSE: 0.5194573198926367\u001b[0m\n",
      "\u001b[34mMAE: 0.5313754750719686\u001b[0m\n",
      "\u001b[34mR2: 0.6074287995577687\u001b[0m\n",
      "\u001b[34mmodel persisted at /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2024-09-16 17:57:06,101 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-09-16 17:57:12 Training - Training image download completed. Training in progress.\n",
      "2024-09-16 17:57:12 Uploading - Uploading generated training model\n",
      "2024-09-16 17:57:24 Completed - Training job completed\n",
      "Training seconds: 119\n",
      "Billable seconds: 47\n",
      "Managed Spot Training savings: 60.5%\n"
     ]
    }
   ],
   "source": [
    "train_s3_path = f\"s3://{s3_bucket}/{s3_location_train}\"\n",
    "test_s3_path = f\"s3://{s3_bucket}/{s3_location_test}\"\n",
    "sklearn_estimator.fit({\"train\": train_s3_path, \"test\": test_s3_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0567c98-fc07-420b-8efe-4a5359834420",
   "metadata": {},
   "source": [
    "## Compute Predictions in Bulk\n",
    "\n",
    "- Define the model to use\n",
    "- Define the git repo with the code that will be used (inference.py)\n",
    "- Define the input data and the model location\n",
    "- Define the output location in S3 where predictions will go\n",
    "\n",
    "This aims to simulate generating predictions on a trained model. This could be done in the model training process itself, but is meant to reflect a more practical scenario where predictions are generated against a model in production.\n",
    "\n",
    "We will reuse the SKLearn container image here, this is explicitly there for model training, but it can be repurposed for batch predictions as well. If real-time predictions are required, we can follow a different process to stand up an API. We also could leverage other services (Glue, SageMaker Batch Transform, even Lambda if model is small enough), but we'll use this approach for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c27541-d65a-4228-bef9-b70a7571180b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define git config\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "git_config = {'repo': 'https://github.com/WesleyPasfield/sagemaker_demo.git'}\n",
    "framework_version = '1.2-1'\n",
    "output_root = 'housingdemo/output'\n",
    "training_job_name = sklearn_estimator._current_job_name\n",
    "\n",
    "sklearn_predict = SKLearn(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir='initial_demo',\n",
    "    role=get_execution_role(),\n",
    "    framework_version=framework_version,\n",
    "    use_spot_instances=True,\n",
    "    max_wait=1000,\n",
    "    max_run = 800,\n",
    "    output_path= f's3://{s3_bucket}/{output_root}/prediction_output/{training_job_name}/',\n",
    "    instance_count=1, # Flexibility if parallizable\n",
    "    instance_type=\"ml.m5.large\",  # Flexibility to scale up if needed\n",
    "    base_job_name=\"rf-preds\",\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"max_depth\": 4,\n",
    "        \"target\": \"target\"\n",
    "    },\n",
    "    git_config=git_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6156b43-151c-4970-ba7a-a129a66879c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/tmp/tmp7jzlhpmi'...\n",
      "INFO:sagemaker:Creating training-job with name: rf-preds-2024-09-16-17-58-03-817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-16 17:58:05 Starting - Starting the training job...\n",
      "2024-09-16 17:58:19 Starting - Preparing the instances for training...\n",
      "2024-09-16 17:59:07 Downloading - Downloading the training image......\n",
      "2024-09-16 18:00:08 Training - Training image download completed. Training in progress..\u001b[34m2024-09-16 18:00:10,791 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:10,794 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:10,797 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:10,814 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,090 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,094 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,111 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,114 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,132 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,134 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,149 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_depth\": 4,\n",
      "        \"min-samples-leaf\": 3,\n",
      "        \"n-estimators\": 100,\n",
      "        \"target\": \"target\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"rf-preds-2024-09-16-17-58-03-817\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://censussmdemo/rf-preds-2024-09-16-17-58-03-817/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"inference\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"inference.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"max_depth\":4,\"min-samples-leaf\":3,\"n-estimators\":100,\"target\":\"target\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=inference.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=inference\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://censussmdemo/rf-preds-2024-09-16-17-58-03-817/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max_depth\":4,\"min-samples-leaf\":3,\"n-estimators\":100,\"target\":\"target\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"rf-preds-2024-09-16-17-58-03-817\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://censussmdemo/rf-preds-2024-09-16-17-58-03-817/source/sourcedir.tar.gz\",\"module_name\":\"inference\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"inference.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--max_depth\",\"4\",\"--min-samples-leaf\",\"3\",\"--n-estimators\",\"100\",\"--target\",\"target\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=4\u001b[0m\n",
      "\u001b[34mSM_HP_MIN-SAMPLES-LEAF=3\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=target\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python inference.py --max_depth 4 --min-samples-leaf 3 --n-estimators 100 --target target\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,150 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:11,150 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34mreading data\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\u001b[0m\n",
      "\u001b[34m[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\u001b[0m\n",
      "\u001b[34mpredictions persisted at /opt/ml/output/data/predictions.csv\u001b[0m\n",
      "\u001b[34m2024-09-16 18:00:12,328 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-09-16 18:00:31 Uploading - Uploading generated training model\n",
      "2024-09-16 18:00:31 Completed - Training job completed\n",
      "Training seconds: 110\n",
      "Billable seconds: 44\n",
      "Managed Spot Training savings: 60.0%\n"
     ]
    }
   ],
   "source": [
    "model_s3_path = f'{sklearn_estimator.output_path}{sklearn_estimator._current_job_name}/output/model.tar.gz'\n",
    "test_s3_path = \"s3://censussmdemo/housingdemo/test/test.csv\"\n",
    "sklearn_predict.fit({\"train\": model_s3_path, \"test\": test_s3_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81281ebe-fe42-400c-8d31-c3513083dcb6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read predictions from S3 to show they are completed\n",
    "# Read from boto3 s3 and convert to dataframe\n",
    "\n",
    "def prediction_reader(s3_bucket, sklearn_predict_job):\n",
    "    pattern = r'^[^/]+://[^/]+/'\n",
    "    s3_location_preds = re.sub(pattern, '', f'{sklearn_predict_job.output_path}{sklearn_predict_job._current_job_name}/output/output.tar.gz')\n",
    "    print(f'S3 location with predictions: {s3_location_preds}')\n",
    "\n",
    "    s3_preds = s3_client.get_object(Bucket=s3_bucket, Key=s3_location_preds)\n",
    "    prediction_raw = s3_preds['Body'].read()\n",
    "\n",
    "    # Create a BytesIO object from the S3 object body\n",
    "    tar_content = io.BytesIO(prediction_raw)\n",
    "\n",
    "    # Open the tarfile\n",
    "    with tarfile.open(fileobj=tar_content, mode='r:gz') as tar:\n",
    "        # Find the first CSV file in the archive\n",
    "        csv_file = next((f for f in tar.getmembers() if f.name.endswith('.csv')), None)\n",
    "\n",
    "        if csv_file is None:\n",
    "            raise ValueError(\"No CSV file found in the tar.gz archive\")\n",
    "\n",
    "        # Extract the CSV file content\n",
    "        csv_content = tar.extractfile(csv_file)\n",
    "\n",
    "        # Read the CSV content into a pandas DataFrame\n",
    "        preds = pd.read_csv(csv_content, header=0)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14438e65-a11d-42eb-9939-bbdc0cdc047f",
   "metadata": {},
   "source": [
    "## Review Predictions\n",
    "\n",
    "After running the model & generating predictions, we can pull predictions down from S3 to review.\n",
    "\n",
    "Note the notebook is just orchestrating the model & prediction generation. We are loading the predictions themselves directly into the notebook environment. Since the predictions are likely smaller, this allows us to scale up to larger compute when needed, but persistently have a smaller instance available for analysis. A helper function to pull in data is hidden in the cell above for reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2036e138-258c-471d-a395-fc5650de0517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 location with predictions: housingdemo/output/prediction_output/rf-scikit-2024-09-16-17-54-45-674/rf-preds-2024-09-16-17-58-03-817/output/output.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.239431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.226810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.162654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.587397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.748417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>3.822272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>1.028411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>1.465872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>3.165391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>3.799839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5160 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # predictions\n",
       "0          1.239431\n",
       "1          1.226810\n",
       "2          3.162654\n",
       "3          2.587397\n",
       "4          1.748417\n",
       "...             ...\n",
       "5155       3.822272\n",
       "5156       1.028411\n",
       "5157       1.465872\n",
       "5158       3.165391\n",
       "5159       3.799839\n",
       "\n",
       "[5160 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "\n",
    "preds = prediction_reader(s3_bucket, sklearn_predict)\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
